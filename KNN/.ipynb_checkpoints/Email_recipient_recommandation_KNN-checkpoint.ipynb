{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Email recipient recommendation</h1>\n",
    "\n",
    "<i>Thomas Boudou, Guillaume Richard, Antoine Simoulin</i>\n",
    "\n",
    "<p style=\"text-align: justify\">It was shown that at work, employees frequently forget to include one or more recipient(s) before sending a message. Conversely, it is common that some recipients of a given message were actually not intended to receive the message. To increase productivity and prevent information leakage, the needs for effective <b>email recipient recommendation</b> systems are thus pressing.\n",
    "\n",
    "In this challenge, you are asked to develop such a system, which, given the content and the date of a message, recommends a list of <b>10 recipients ranked by decreasing order of relevance</b>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Requirements\n",
    "%matplotlib inline\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# do not display warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Functions files are saved in \"src/\" directory.\n",
    "import sys\n",
    "sys.path.append('src/')\n",
    "from accuracy_measure import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from load_data import *\n",
    "\n",
    "# load files\n",
    "# Data are saved in \"data/\" directory\n",
    "path_to_data = '../data/'\n",
    "training, training_info, test, test_info, y_df = load_data(path_to_data)\n",
    "\n",
    "# create adress book\n",
    "# /!\\ can take 1-2 min\n",
    "address_books = create_address_books(training, y_df)\n",
    "\n",
    "# join train and test files\n",
    "X_df = join_data(training_info, training)\n",
    "X_sub_df = join_data(test_info, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KNN(distance,k=30):\n",
    "    indexes=[]\n",
    "    for d in distance:\n",
    "        indexes.append((-d).argsort()[:k])\n",
    "    return np.array(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "\n",
    "class TFIDF():\n",
    "    def __init__(self):\n",
    "        self.token_dict = {}\n",
    "        self.tfidf=TfidfVectorizer(tokenizer=None, stop_words='english')\n",
    "\n",
    "    def fit(self, X):\n",
    "        for i in range(X.shape[0]):\n",
    "            text = X.body.values[i]\n",
    "            lowers = text.lower()\n",
    "            s=string.punctuation.replace('@','')\n",
    "            s=s.replace('+','')\n",
    "            no_punctuation = lowers.translate(str.maketrans('','',s))\n",
    "            y = \" \".join(no_punctuation.split())\n",
    "            y = ' '.join([word for word in y.split() if word not in cachedStopWords])\n",
    "            self.token_dict[i] = y\n",
    "\n",
    "        self.tfidf.fit(self.token_dict.values())\n",
    "\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        start_time = time.time()\n",
    "        for i in range(X.shape[0]):\n",
    "            text = X.body.values[i]\n",
    "            lowers = text.lower()\n",
    "            s=string.punctuation.replace('@','')\n",
    "            s=s.replace('+','')\n",
    "\n",
    "            no_punctuation = lowers.translate(str.maketrans('','',s))\n",
    "            y = \" \".join(no_punctuation.split())\n",
    "            y = ' '.join([word for word in y.split() if word not in cachedStopWords])\n",
    "\n",
    "            self.token_dict[i] = y\n",
    "\n",
    "        X_tfidf = self.tfidf.fit_transform(self.token_dict.values())\n",
    "\n",
    "        print('performed Tf-Idf in %2i seconds.' % (time.time() - start_time))\n",
    "        return X_tfidf\n",
    "\n",
    "    def transform(self, Y):\n",
    "        start_time = time.time()\n",
    "        Y_dict={}\n",
    "        for i in range(Y.shape[0]):\n",
    "            text = Y.body.values[i]\n",
    "            lowers = text.lower()\n",
    "            s=string.punctuation.replace('@','')\n",
    "            s=s.replace('+','')\n",
    "\n",
    "            no_punctuation = lowers.translate(str.maketrans('','',s))\n",
    "            y = \" \".join(no_punctuation.split())\n",
    "            y = ' '.join([word for word in y.split() if word not in cachedStopWords])\n",
    "\n",
    "            Y_dict[i] = y\n",
    "        Y_tf_idf=self.tfidf.transform(Y_dict.values())\n",
    "\n",
    "        print('performed Tf-Idf in %2i seconds.' % (time.time() - start_time))\n",
    "        return Y_tf_idf\n",
    "\n",
    "def complete_prediction(k, sender, address_books, res_temp, K=10):\n",
    "    # k the number of recipients to predict\n",
    "    k_most = [elt[0] for elt in address_books[sender][:K] if elt not in res_temp]\n",
    "    k_most = k_most[:k]\n",
    "    if len(k_most) < k: # sender n'a pas assez de contacts\n",
    "        k_most.extend([0] * (k-len(k_most)))\n",
    "    return k_most\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Fitting </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Cross-Validation Module--------\n",
      "\n",
      " Beginning of extraction \n",
      " ------------\n",
      "performed Tf-Idf in 17 seconds.\n",
      "performed Tf-Idf in  5 seconds.\n",
      "Extraction done \n",
      " ------------\n",
      "\n",
      " Beginning of prediction \n",
      " ------------\n",
      "0 / 125\n",
      "1 / 125\n",
      "2 / 125\n",
      "3 / 125\n",
      "4 / 125\n",
      "5 / 125\n",
      "6 / 125\n",
      "7 / 125\n",
      "8 / 125\n",
      "9 / 125\n",
      "10 / 125\n",
      "11 / 125\n",
      "12 / 125\n",
      "13 / 125\n",
      "14 / 125\n",
      "15 / 125\n",
      "16 / 125\n",
      "17 / 125\n",
      "18 / 125\n",
      "19 / 125\n",
      "20 / 125\n",
      "21 / 125\n",
      "22 / 125\n",
      "23 / 125\n",
      "24 / 125\n",
      "25 / 125\n",
      "26 / 125\n",
      "27 / 125\n",
      "28 / 125\n",
      "29 / 125\n",
      "30 / 125\n",
      "31 / 125\n",
      "32 / 125\n",
      "33 / 125\n",
      "34 / 125\n",
      "35 / 125\n",
      "36 / 125\n",
      "37 / 125\n",
      "38 / 125\n",
      "39 / 125\n",
      "40 / 125\n",
      "41 / 125\n",
      "42 / 125\n",
      "43 / 125\n",
      "44 / 125\n",
      "45 / 125\n",
      "46 / 125\n",
      "47 / 125\n",
      "48 / 125\n",
      "49 / 125\n",
      "50 / 125\n",
      "51 / 125\n",
      "52 / 125\n",
      "53 / 125\n",
      "54 / 125\n",
      "55 / 125\n",
      "56 / 125\n",
      "57 / 125\n",
      "58 / 125\n",
      "59 / 125\n",
      "60 / 125\n",
      "61 / 125\n",
      "62 / 125\n",
      "63 / 125\n",
      "64 / 125\n",
      "65 / 125\n",
      "66 / 125\n",
      "67 / 125\n",
      "68 / 125\n",
      "69 / 125\n",
      "70 / 125\n",
      "71 / 125\n",
      "72 / 125\n",
      "73 / 125\n",
      "74 / 125\n",
      "75 / 125\n",
      "76 / 125\n",
      "77 / 125\n",
      "78 / 125\n",
      "79 / 125\n",
      "80 / 125\n",
      "81 / 125\n",
      "82 / 125\n",
      "83 / 125\n",
      "84 / 125\n",
      "85 / 125\n",
      "86 / 125\n",
      "87 / 125\n",
      "88 / 125\n",
      "89 / 125\n",
      "90 / 125\n",
      "91 / 125\n",
      "92 / 125\n",
      "93 / 125\n",
      "94 / 125\n",
      "95 / 125\n",
      "96 / 125\n",
      "97 / 125\n",
      "98 / 125\n",
      "99 / 125\n",
      "100 / 125\n",
      "101 / 125\n",
      "102 / 125\n",
      "103 / 125\n",
      "104 / 125\n",
      "105 / 125\n",
      "106 / 125\n",
      "107 / 125\n",
      "108 / 125\n",
      "109 / 125\n",
      "110 / 125\n",
      "111 / 125\n",
      "112 / 125\n",
      "113 / 125\n",
      "114 / 125\n",
      "115 / 125\n",
      "116 / 125\n",
      "117 / 125\n",
      "118 / 125\n",
      "119 / 125\n",
      "120 / 125\n",
      "121 / 125\n",
      "122 / 125\n",
      "123 / 125\n",
      "124 / 125\n",
      "CPU times: user 2h 31min 28s, sys: 1min 45s, total: 2h 33min 14s\n",
      "Wall time: 42min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#import TFIDF_mod\n",
    "#from TFIDF_mod import TFIDF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# splitting data for cross validation\n",
    "skf = ShuffleSplit(n_splits=1, test_size=0.25)\n",
    "\n",
    "print('--------Cross-Validation Module--------')\n",
    "for train_is, test_is in skf.split(y_df):\n",
    "    print('\\n Beginning of extraction \\n ------------')\n",
    "    ############Extraction + TF-IDF############\n",
    "    X_train=X_df.ix[train_is]\n",
    "    y_train = y_df.recipients.loc[train_is].copy()\n",
    "    X_test=X_df.ix[test_is]\n",
    "    y_test = y_df.recipients.loc[test_is].copy()\n",
    "    y_pred=y_test.copy()\n",
    "    \n",
    "    tf_idf = TFIDF()\n",
    "    X_train_TFIDF=tf_idf.fit_transform(X_train)\n",
    "    X_test_TFIDF=tf_idf.transform(X_test)\n",
    "    print('Extraction done \\n ------------')\n",
    "    print('\\n Beginning of prediction \\n ------------')\n",
    "    ############Prediction############\n",
    "    sender_test = X_test.sender.unique().tolist()\n",
    "    clf={}\n",
    "    count=0\n",
    "    L=len(sender_test)\n",
    "    y_pred=y_test.copy()\n",
    "\n",
    "    for sender in sender_test:\n",
    "        #Isolation of sender's mails\n",
    "        sender_train_is = np.array(X_train.sender == sender)\n",
    "        sender_test_is = np.array(X_test.sender == sender)\n",
    "\n",
    "        ############Feature extraction############\n",
    "        #Finding the nearest neighbours of sender's mails\n",
    "        cos_dist_mat=cosine_similarity(X_train_TFIDF[sender_train_is])-np.identity(sum(sender_train_is))\n",
    "        cos_dist_mat_test=cosine_similarity(X_test_TFIDF[sender_test_is],X_train_TFIDF[sender_train_is])\n",
    "        #cos_dist_mat=cosine_similarity(X_TFIDF[sender_train_is],X_TFIDF) #to try later\n",
    "        KNN_indices=KNN(cos_dist_mat,k=30)\n",
    "        KNN_indices_test=KNN(cos_dist_mat_test,k=30)\n",
    "\n",
    "        #Sender number in the address book\n",
    "        sender_AB={}\n",
    "        id_to_sender={}\n",
    "        z=0\n",
    "        for x in address_books[sender]:\n",
    "            sender_AB[x[0]]=z\n",
    "            id_to_sender[z]=x[0]\n",
    "            z=z+1\n",
    "\n",
    "        #Creation of the score vector\n",
    "        recipient_scores=np.zeros((sum(sender_train_is),len(sender_AB)))\n",
    "        for i in range(sum(sender_train_is)):\n",
    "            d=np.array(KNN_indices[i])\n",
    "            neigh_mails=y_train.values[d]#neighbour mails\n",
    "            z=0\n",
    "            for n_mail in neigh_mails:\n",
    "                for rec in n_mail:\n",
    "                    if rec in sender_AB:\n",
    "                        j=sender_AB[rec]#index in the score vector\n",
    "                        recipient_scores[i,j]+=cos_dist_mat[i,d[z]]\n",
    "                z=z+1\n",
    "\n",
    "        ############Train############\n",
    "\n",
    "        #Creation of the labels for the classifier\n",
    "        recipient_labels=np.zeros((sum(sender_train_is),len(sender_AB)))\n",
    "        i=0\n",
    "        for rec_list in y_train[sender_train_is]:\n",
    "            for rec in rec_list:\n",
    "                if rec in sender_AB:\n",
    "                    j=sender_AB[rec]\n",
    "                    recipient_labels[i,j]=1 \n",
    "            i=i+1\n",
    "\n",
    "        #One classifier per recipient\n",
    "        for rec in sender_AB:\n",
    "            key=sender+','+rec\n",
    "            #clf[key]=SVC()\n",
    "            clf[key]=xgb.XGBClassifier(n_estimators=50)\n",
    "            clf[key].fit(recipient_scores,recipient_labels.T[sender_AB[rec]])\n",
    "\n",
    "\n",
    "        ############Test############\n",
    "\n",
    "        #Creation of the test score vector\n",
    "        recipient_scores=np.zeros((sum(sender_test_is),len(sender_AB)))\n",
    "        for i in range(sum(sender_test_is)):\n",
    "            d=np.array(KNN_indices[i])\n",
    "            neigh_mails=y_train.values[d]#neighbour mails\n",
    "            z=0\n",
    "            for n_mail in neigh_mails:\n",
    "                for rec in n_mail:\n",
    "                    if rec in sender_AB:\n",
    "                        j=sender_AB[rec]#index in the score vector\n",
    "                        recipient_scores[i,j]+=cos_dist_mat[i,d[z]]\n",
    "                z=z+1\n",
    "\n",
    "        recipient_labels=np.zeros((sum(sender_test_is),len(sender_AB))).T\n",
    "\n",
    "        #Prediction\n",
    "        pred=0\n",
    "        for rec in sender_AB:\n",
    "            key=sender+','+rec\n",
    "            recipient_labels[sender_AB[rec]]=(clf[key].predict_proba(recipient_scores)).T[1].T\n",
    "        recipient_labels=recipient_labels.T\n",
    "        #Storage\n",
    "        y_test_pred=[]\n",
    "        for y in recipient_labels:\n",
    "            y_tmp=[]\n",
    "            max_rec=(-y).argsort()[:10]\n",
    "            for rec_id in max_rec:\n",
    "                y_tmp.append(id_to_sender[rec_id])\n",
    "            if len(y_tmp) < 10:\n",
    "                y_tmp.extend(complete_prediction(10-len(y_tmp),sender, address_books, y_tmp))\n",
    "            y_test_pred.append(y_tmp)\n",
    "        y_pred.ix[sender_test_is]=y_test_pred\n",
    "        print(count,'/',L)\n",
    "        count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0 |                    rahil.jafry@enron.com | 0.48\n",
      "         1 |                      eric.bass@enron.com | 0.18\n",
      "         2 |                    susan.scott@enron.com | 0.05\n",
      "         3 |                  karen.buckley@enron.com | 0.25\n",
      "         4 |                    karen.denne@enron.com | 0.43\n",
      "         5 |                  john.lavorato@enron.com | 0.1\n",
      "         6 |                  chris.germany@enron.com | 0.06\n",
      "         7 |                  michelle.cash@enron.com | 0.13\n",
      "         8 |                sara.shackleton@enron.com | 0.08\n",
      "         9 |               hunter.s.shively@enron.com | 0.16\n",
      "        10 |                     sally.beck@enron.com | 0.08\n",
      "        11 |                     lynn.blair@enron.com | 0.23\n",
      "        12 |                    amr.ibrahim@enron.com | 0.52\n",
      "        13 |                  chris.dorland@enron.com | 0.07\n",
      "        14 |                richard.shapiro@enron.com | 0.35\n",
      "        15 |                       c..giron@enron.com | 0.09\n",
      "        16 |                 ginger.dernehl@enron.com | 0.51\n",
      "        17 |                     tim.belden@enron.com | 0.18\n",
      "        18 |                christian.yoder@enron.com | 0.26\n",
      "        19 |                       rick.buy@enron.com | 0.07\n",
      "        20 |                  becky.spencer@enron.com | 0.39\n",
      "        21 |                    mike.carson@enron.com | 0.17\n",
      "        22 |                      l..denton@enron.com | 0.91\n",
      "        23 |        enron_update@concureworkplace.com | 0.15\n",
      "        24 |                 stanley.horton@enron.com | 0.1\n",
      "        25 |                         taylor@enron.com | 0.05\n",
      "        26 |          nancy.sellers@robertmondavi.com | 0.87\n",
      "        27 |                       kim.ward@enron.com | 0.1\n",
      "        28 |                 kevin.m.presto@enron.com | 0.11\n",
      "        29 |                  martin.cuilla@enron.com | 0.18\n",
      "        30 |                     scott.neal@enron.com | 0.11\n",
      "        31 |                  lorna.brennan@enron.com | 0.79\n",
      "        32 |                  john.zufferli@enron.com | 0.1\n",
      "        33 |                     wsmith@wordsmith.org | 1.0\n",
      "        34 |                james.d.steffes@enron.com | 0.16\n",
      "        35 |                 stacey.w.white@enron.com | 0.47\n",
      "        36 |                  peter.keohane@enron.com | 0.21\n",
      "        37 |               errol.mclaughlin@enron.com | 0.07\n",
      "        38 |                   beth.cherry@enform.com | 0.82\n",
      "        39 |                    andy.zipper@enron.com | 0.09\n",
      "        40 |               fletcher.j.sturm@enron.com | 0.04\n",
      "        41 |                   mike.grigsby@enron.com | 0.27\n",
      "        42 |                        vkaminski@aol.com | 0.75\n",
      "        43 |                 phillip.m.love@enron.com | 0.07\n",
      "        44 |    schwabalerts.marketupdates@schwab.com | 1.0\n",
      "        45 |                  james.derrick@enron.com | 0.23\n",
      "        46 |                 jonathan.mckay@enron.com | 0.13\n",
      "        47 |               holden.salisbury@enron.com | 0.11\n",
      "        48 |                  sheila.glover@enron.com | 0.44\n",
      "        49 |                    alan.comnes@enron.com | 0.31\n",
      "        50 |                     david.port@enron.com | 0.24\n",
      "        51 |                      m..forney@enron.com | 0.16\n",
      "        52 |                 heather.dunton@enron.com | 0.49\n",
      "        53 |                   megan.parker@enron.com | 0.88\n",
      "        54 |                   shona.wilson@enron.com | 0.32\n",
      "        55 |               stephanie.miller@enron.com | 0.46\n",
      "        56 |                stephanie.panus@enron.com | 0.33\n",
      "        57 |                 patrice.l.mims@enron.com | 0.14\n",
      "        58 |                     matt.smith@enron.com | 0.06\n",
      "        59 |                     mike.maggi@enron.com | 0.72\n",
      "        60 |                      mary.cook@enron.com | 0.28\n",
      "        61 |                     bob.shults@enron.com | 0.26\n",
      "        62 |                    marie.heard@enron.com | 0.09\n",
      "        63 |                  paul.d.thomas@enron.com | 0.16\n",
      "        64 |                     ben.jacoby@enron.com | 0.49\n",
      "        65 |            darrell.schoolcraft@enron.com | 0.28\n",
      "        66 |             kenneth.thibodeaux@enron.com | 0.74\n",
      "        67 |               monika.causholli@enron.com | 0.3\n",
      "        68 |                     greg.piper@enron.com | 0.33\n",
      "        69 |                 mark.mcconnell@enron.com | 0.14\n",
      "        70 |                   holly.keiser@enron.com | 0.39\n",
      "        71 |                    cindy.stark@enron.com | 0.14\n",
      "        72 |                       jbennett@gmssr.com | 0.39\n",
      "        73 |               sandra.f.brawner@enron.com | 0.19\n",
      "        74 |                     m..schmidt@enron.com | 0.93\n",
      "        75 |                      jean.mrha@enron.com | 0.43\n",
      "        76 |               marcus.nettelton@enron.com | 0.51\n",
      "        77 |                     liz.taylor@enron.com | 0.25\n",
      "        78 |                     mark.whitt@enron.com | 0.2\n",
      "        79 |                 keegan.farrell@enron.com | 0.55\n",
      "        80 |                   paul.y barbo@enron.com | 0.08\n",
      "        81 |                 mark.greenberg@enron.com | 0.37\n",
      "        82 |               michael.tribolet@enron.com | 0.39\n",
      "        83 |                 janel.guerrero@enron.com | 0.51\n",
      "        84 |                  tanya.rohauer@enron.com | 0.31\n",
      "        85 |                 justin.rostant@enron.com | 0.57\n",
      "        86 |                kimberly.hillis@enron.com | 0.17\n",
      "        87 |                 barry.tycholiz@enron.com | 0.15\n",
      "        88 |                     l..nicolay@enron.com | 0.27\n",
      "        89 |                  david.forster@enron.com | 0.32\n",
      "        90 |                  dutch.quigley@enron.com | 0.12\n",
      "        91 |                     jane.tholt@enron.com | 0.07\n",
      "        92 |                   paul.kaufman@enron.com | 0.44\n",
      "        93 |                tori.kuykendall@enron.com | 0.07\n",
      "        94 |                     brad.mckay@enron.com | 0.26\n",
      "        95 |                grace.rodriguez@enron.com | 0.3\n",
      "        96 |               larry.f.campbell@enron.com | 0.14\n",
      "        97 |                    jason.wolfe@enron.com | 0.22\n",
      "        98 |                amy.fitzpatrick@enron.com | 0.55\n",
      "        99 |               christina.valdez@enron.com | 0.67\n",
      "       100 |                 jason.williams@enron.com | 0.11\n",
      "       101 |                 cheryl.johnson@enron.com | 0.76\n",
      "       102 |                  jim.schwieger@enron.com | 0.15\n",
      "       103 |                 alan.aronowitz@enron.com | 0.19\n",
      "       104 |                  brian.redmond@enron.com | 0.35\n",
      "       105 |                    w..cantrell@enron.com | 0.57\n",
      "       106 |                    andrea.ring@enron.com | 0.14\n",
      "       107 |                    britt.davis@enron.com | 0.29\n",
      "       108 |              kathleen.carnahan@enron.com | 0.75\n",
      "       109 |                  andrew.edison@enron.com | 0.24\n",
      "       110 |                julie.armstrong@enron.com | 0.48\n",
      "       111 |             joannie.williamson@enron.com | 0.29\n",
      "       112 |                    david.portz@enron.com | 0.39\n",
      "       113 |               joe.stepenovitch@enron.com | 0.42\n",
      "       114 |                 jennifer.thome@enron.com | 0.53\n",
      "       115 |                    c..williams@enron.com | 0.27\n",
      "       116 |                harry.kingerski@enron.com | 0.24\n",
      "       117 |                russell.diamond@enron.com | 0.2\n",
      "       118 |                            alex@pira.com | 1.0\n",
      "       119 |                phillip.platter@enron.com | 0.18\n",
      "       120 |                lisa.mellencamp@enron.com | 0.16\n",
      "       121 |                      sylvia.hu@enron.com | 0.3\n",
      "       122 |                  suzanne.adams@enron.com | 0.6\n",
      "       123 |                stephanie.sever@enron.com | 0.35\n",
      "       124 |                    mark.palmer@enron.com | 0.35\n",
      "0.324563121385\n"
     ]
    }
   ],
   "source": [
    "for train_is, test_is in skf.split(y_df):\n",
    "    \n",
    "    \n",
    "    i=0\n",
    "    accuracy = {}\n",
    "    accuracy_freq = {}\n",
    "    accuracy_TOT = 0\n",
    "    for sender in sender_test:\n",
    "        print('%10s | %40s | ' %(sender_test.index(sender), sender), end='')\n",
    "        sender_train_is = np.array(X_train.sender == sender)\n",
    "        sender_test_is = np.array(X_test.sender == sender)\n",
    "        \n",
    "        accuracy[sender] = mapk(y_test[sender_test_is], y_pred[sender_test_is])\n",
    "        \n",
    "        accuracy_TOT += accuracy[sender]\n",
    "        print(round(accuracy[sender],2))\n",
    "print(accuracy_TOT/len(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10636                               [tana.jones@enron.com]\n",
       " 43339    [kenneth.lay@enron.com, james.derrick@enron.co...\n",
       " 22600    [richard.shapiro@enron.com, eric.thode@enron.c...\n",
       " 25527                            [jeff.dasovich@enron.com]\n",
       " 10931    [kevin.montagne@enron.com, tana.jones@enron.co...\n",
       " 14158                            [steven.j.kean@enron.com]\n",
       " 22699    [richard.shapiro@enron.com, steven.j.kean@enro...\n",
       " 22700    [richard.shapiro@enron.com, steven.j.kean@enro...\n",
       " 13605                            [steven.j.kean@enron.com]\n",
       " 14116    [richard.shapiro@enron.com, steven.j.kean@enro...\n",
       " 14071    [james.d.steffes@enron.com, richard.shapiro@en...\n",
       " 10928    [stephanie.segura@enron.com, irma.fuentes@enro...\n",
       " 13709                            [steven.j.kean@enron.com]\n",
       " 13778    [james.d.steffes@enron.com, richard.shapiro@en...\n",
       " 2850     [richard.shapiro@enron.com, steven.j.kean@enro...\n",
       " 14079                            [steven.j.kean@enron.com]\n",
       " 43332    [paula.rieker@enron.com, kenneth.lay@enron.com...\n",
       " 13821    [james.d.steffes@enron.com, steven.j.kean@enro...\n",
       " 10911                               [tana.jones@enron.com]\n",
       " 14382    [linda.robertson@enron.com, richard.shapiro@en...\n",
       " 13789    [paul.kaufman@enron.com, richard.shapiro@enron...\n",
       " 13833    [ken.@kdscommunications.com, janel.guerrero@en...\n",
       " 10790                               [tana.jones@enron.com]\n",
       " 33797    [greg.whalley@enron.com, john.lavorato@enron.c...\n",
       " 33935                               [j.kaminski@enron.com]\n",
       " Name: recipients, dtype: object,\n",
       " 10636    [richard.shapiro@enron.com, steven.j.kean@enro...\n",
       " 43339    [paul.kaufman@enron.com, steven.j.kean@enron.c...\n",
       " 22600    [steven.j.kean@enron.com, kelly.kimberly@enron...\n",
       " 25527    [steven.j.kean@enron.com, richard.shapiro@enro...\n",
       " 10931    [steven.j.kean@enron.com, james.d.steffes@enro...\n",
       " 14158    [paul.kaufman@enron.com, steven.j.kean@enron.c...\n",
       " 22699    [steven.j.kean@enron.com, kenneth.lay@enron.co...\n",
       " 22700    [steven.j.kean@enron.com, james.d.steffes@enro...\n",
       " 13605    [steven.j.kean@enron.com, paula.rieker@enron.c...\n",
       " 14116    [jeff.skilling@enron.com, steven.j.kean@enron....\n",
       " 14071    [james.d.steffes@enron.com, steven.j.kean@enro...\n",
       " 10928    [steven.j.kean@enron.com, karen.denne@enron.co...\n",
       " 13709    [steven.j.kean@enron.com, david.w.delainey@enr...\n",
       " 13778    [steven.j.kean@enron.com, karen.denne@enron.co...\n",
       " 2850     [steven.j.kean@enron.com, james.d.steffes@enro...\n",
       " 14079    [steven.j.kean@enron.com, kenneth.lay@enron.co...\n",
       " 43332    [louise.kitchen@enron.com, steven.j.kean@enron...\n",
       " 13821    [steven.j.kean@enron.com, richard.shapiro@enro...\n",
       " 10911    [louise.kitchen@enron.com, linda.robertson@enr...\n",
       " 14382    [tana.jones@enron.com, vance.meyer@enron.com, ...\n",
       " 13789    [tana.jones@enron.com, steven.j.kean@enron.com...\n",
       " 13833    [steven.j.kean@enron.com, paula.rieker@enron.c...\n",
       " 10790    [steven.j.kean@enron.com, karen.denne@enron.co...\n",
       " 33797    [steven.j.kean@enron.com, karen.denne@enron.co...\n",
       " 33935    [steven.j.kean@enron.com, james.d.steffes@enro...\n",
       " Name: recipients, dtype: object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[sender_test_is], y_pred[sender_test_is]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def complete_prediction(k, sender, address_books, res_temp, K=10):\n",
    "    # k the number of recipients to predict\n",
    "    k_most = [elt[0] for elt in address_books[sender][:K] if elt not in res_temp]\n",
    "    k_most = k_most[:k]\n",
    "    if len(k_most) < k: # sender n'a pas assez de contacts\n",
    "        k_most.extend([0] * (k-len(k_most)))\n",
    "    return k_most\n",
    "\n",
    "class Predictor_2():\n",
    "    def __init__(self, X, y, sender, address_books,N=10):\n",
    "        self.train = X\n",
    "        self.predict = y.values\n",
    "        self.sender = sender\n",
    "        self.N = min(N,10)\n",
    "        self.address_books = address_books\n",
    "\n",
    "    def predict_2(self, X):\n",
    "        res = []\n",
    "        for i in range(X.shape[0]):\n",
    "            cos = (-cosine_similarity(X[i],self.train)).argsort()[:,:30][0] # 30 mails les plus proches\n",
    "            if self.N != 0:\n",
    "                NN_recpt = {}\n",
    "                for j in range(30):\n",
    "                    for k in range(len(self.predict[cos[j]])):\n",
    "                        if self.predict[cos[j]][k] in NN_recpt:\n",
    "                            NN_recpt[self.predict[cos[j]][k]]+= cosine_similarity(X[i],self.train[cos[j]])\n",
    "                        else:\n",
    "                            NN_recpt[self.predict[cos[j]][k]] = cosine_similarity(X[i],self.train[cos[j]])\n",
    "                res_temp = list(dict(sorted(NN_recpt.items(), key=operator.itemgetter(1), reverse=True)[:10]))\n",
    "                #res_temp = [self.predict[cos][0][:self.N]] # add the N first recipients of the closest e-mail\n",
    "            else:\n",
    "                 res_temp = []\n",
    "            # if less than 10 recipients, complete the prediction with more frequents users\n",
    "            if len(res_temp) < 10:\n",
    "                res_temp.extend(complete_prediction(10-len(res_temp),self.sender, self.address_books, res_temp))\n",
    "            res.append(res_temp)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sender_nb |                                   sender |  accuracy KNN | accuracy freq\n",
      "---------- + ---------------------------------------- + ------------- + -------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# splitting data for cross validation\n",
    "skf = ShuffleSplit(n_splits=1, test_size=0.2)\n",
    "print('%10s | %40s | %13s | %13s' %('sender_nb', 'sender', 'accuracy KNN','accuracy freq'))\n",
    "print('%10s + %40s + %13s + %13s' %(10*'-', 40*'-', 13*'-', 13*'-'))\n",
    "\n",
    "for train_is, test_is in skf.split(y_df):\n",
    "    \n",
    "    X_tfidf_train = X_TFIDF[train_is].copy()\n",
    "    y_train = y_df.recipients.loc[train_is].copy()\n",
    "    X_tfidf_test = X_TFIDF[test_is].copy()\n",
    "    y_test = y_df.recipients.loc[test_is].copy()\n",
    "    X_test_df = X_df.loc[test_is].copy()\n",
    "    X_train_df = X_df.loc[train_is].copy()\n",
    "    \n",
    "    i=0\n",
    "    pdt = {}\n",
    "    pdt_freq = {}\n",
    "    accuracy = {}\n",
    "    accuracy_freq = {}\n",
    "    accuracy_TOT = 0\n",
    "    sender_test = X_test_df.sender.unique().tolist()\n",
    "    y_pred = np.empty((X_test_df.shape[0],10),dtype=object)\n",
    "    y_pred_freq = np.empty((X_test_df.shape[0],10),dtype=object)\n",
    "    for sender in sender_test:\n",
    "        print('%10s | %40s | ' %(sender_test.index(sender), sender), end='')\n",
    "        # indices corresponding to the sender\n",
    "        sender_train_is = np.array(X_train_df.sender == sender)\n",
    "        sender_test_is = np.array(X_test_df.sender == sender)\n",
    "        \n",
    "        pdt[sender] = Predictor_2(X_tfidf_train[sender_train_is], y_train[sender_train_is], sender, address_books)\n",
    "        pdt_freq[sender] = Predictor_2(X_tfidf_train[sender_train_is], y_train[sender_train_is], sender, address_books, N=0)\n",
    "        y_pred[sender_test_is] = pdt[sender].predict_2(X_tfidf_test[sender_test_is])\n",
    "        y_pred_freq[sender_test_is] = pdt_freq[sender].predict_2(X_tfidf_test[sender_test_is])\n",
    "        \n",
    "        accuracy[sender] = mapk(y_test[sender_test_is], y_pred[sender_test_is])\n",
    "        accuracy_freq[sender] = mapk(y_test[sender_test_is], y_pred_freq[sender_test_is])\n",
    "        \n",
    "        accuracy_TOT += accuracy[sender]\n",
    "        print('%13s | %13s' %(round(accuracy[sender],2),round(accuracy_freq[sender],2)))\n",
    "\n",
    "\n",
    "    print('%30s'%(90*'-'))\n",
    "    print('error TOT = %.2f' %(accuracy_TOT/len(accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
