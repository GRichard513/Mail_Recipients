{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Email recipient recommendation</h1>\n",
    "\n",
    "<i>Thomas Boudou, Guillaume Richard, Antoine Simoulin</i>\n",
    "\n",
    "<p style=\"text-align: justify\">It was shown that at work, employees frequently forget to include one or more recipient(s) before sending a message. Conversely, it is common that some recipients of a given message were actually not intended to receive the message. To increase productivity and prevent information leakage, the needs for effective <b>email recipient recommendation</b> systems are thus pressing.\n",
    "\n",
    "In this challenge, you are asked to develop such a system, which, given the content and the date of a message, recommends a list of <b>10 recipients ranked by decreasing order of relevance</b>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Requirements\n",
    "%matplotlib inline\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# do not display warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Functions files are saved in \"src/\" directory.\n",
    "import sys\n",
    "sys.path.append('src/')\n",
    "from accuracy_measure import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from load_data import *\n",
    "\n",
    "# load files\n",
    "# Data are saved in \"data/\" directory\n",
    "path_to_data = 'data/'\n",
    "training, training_info, test, test_info, y_df = load_data(path_to_data)\n",
    "\n",
    "# create adress book\n",
    "# /!\\ can take 1-2 min\n",
    "address_books = create_address_books(training, y_df)\n",
    "\n",
    "# join train and test files\n",
    "X_df = join_data(training_info, training)\n",
    "X_sub_df = join_data(test_info, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performed Tf-Idf in 26 seconds.\n",
      "performed Tf-Idf in  1 seconds.\n"
     ]
    }
   ],
   "source": [
    "import TFIDF_mod\n",
    "from TFIDF_mod import TFIDF\n",
    "\n",
    "# transform each mail body into tfidf vector\n",
    "# /!\\ function can take 1-2 min to execute\n",
    "TFIDF = TFIDF()\n",
    "X_TFIDF = TFIDF.fit_transform(X_df) # resulting shape : (43613, 275988)\n",
    "X_sub_TFIDF = TFIDF.transform(X_sub_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Predictors</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def complete_prediction(k, sender, address_books, res_temp, K=10):\n",
    "    # k the number of recipients to predict\n",
    "    k_most = [elt[0] for elt in address_books[sender][:K] if elt[0] not in res_temp]\n",
    "    k_most = k_most[:k]\n",
    "    if len(k_most) < k: # sender n'a pas assez de contacts\n",
    "        k_most.extend([0] * (k-len(k_most)))\n",
    "    return k_most"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Predictor closest message with Tf-Idf</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Predictor_TFIDF():\n",
    "    def __init__(self, X, y, sender, address_books,N=10):\n",
    "        self.train = X\n",
    "        self.predict = y.values\n",
    "        self.sender = sender\n",
    "        self.address_books = address_books\n",
    "        self.N = min(N,10)\n",
    "        \n",
    "    def prediction(self, X):\n",
    "        res = []\n",
    "        for i in range(X.shape[0]):\n",
    "            cos = cosine_similarity(X[i],self.train).argsort()[:,0][0] # mail le plus proche\n",
    "            if self.N != 0:\n",
    "                res_temp = [self.predict[cos][0][:self.N]] # add the N first recipients of the closest e-mail\n",
    "            else:\n",
    "                 res_temp = []\n",
    "            # if less than 10 recipients, complete the prediction with more frequents users\n",
    "            if len(res_temp) < 10:\n",
    "                res_temp.extend(complete_prediction(10-len(res_temp),self.sender, self.address_books, res_temp))\n",
    "            res.append(res_temp)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Predictor Tf-Idf centralized centro√Ød</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Predictor_CTFIDF():\n",
    "    def __init__(self, X, y, sender, address_books,N=10):\n",
    "        self.N = min(N,10)\n",
    "        self.train = X\n",
    "        self.predict = y.values\n",
    "        self.sender = sender\n",
    "        self.address_books = address_books\n",
    "        self.X_recpt = {}\n",
    "        \n",
    "        # perform centroid Tf-Idf. i.e each 10 most frequent recipients is represented \n",
    "        # by an average of all mail he received.\n",
    "        # exctract 10 most frequents recipients\n",
    "        self.k_most = [elt[0] for elt in address_books[sender][:10]]\n",
    "        # perform average Tf-Idf on 10 most frequents recipients\n",
    "        for recpt in self.k_most: # loop trough 10 most frequents recipients\n",
    "            self.X_recpt[recpt] = 0\n",
    "            N = 0\n",
    "            for i in range(X.shape[0]): # loop trough all mails send by sender\n",
    "                if recpt in self.predict[i]: # if recipients is in mail\n",
    "                    self.X_recpt[recpt] += X[i]\n",
    "                N +=1\n",
    "            self.X_recpt[recpt] /= N\n",
    "            \n",
    "\n",
    "    def prediction(self, X):\n",
    "        res = []\n",
    "        cos = {}\n",
    "        for i in range(X.shape[0]):\n",
    "            # cosine similarity with 10 most frequents recpt\n",
    "            for recpt, value in self.X_recpt.items():\n",
    "                if isinstance(self.X_recpt[recpt], list): # check that sender has more than 10 recipients\n",
    "                    cos[recpt] = cosine_similarity(X[i],self.X_recpt[recpt]).argsort()[:,0][0]\n",
    "                else:\n",
    "                    cos[recpt] = 1\n",
    "            if self.N != 0:\n",
    "                # return the 10 most frequent recipients in order \n",
    "                # given by similarity to their centroid Tf-Idf representation\n",
    "                res_temp = list(dict(sorted(cos.items(), key=operator.itemgetter(1), reverse=True)[:10]))\n",
    "            else:\n",
    "                 res_temp = []\n",
    "            # if less than 10 recipients, complete the prediction with more frequents users\n",
    "            if len(res_temp) < 10:\n",
    "                res_temp.extend(complete_prediction(10-len(res_temp),self.sender, self.address_books, res_temp))\n",
    "            res.append(res_temp)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Predictor KNN</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Predictor_KNN():\n",
    "    def __init__(self, X, y, sender, address_books,N=10):\n",
    "        self.train = X\n",
    "        self.predict = y.values\n",
    "        self.sender = sender\n",
    "        self.N = min(N,10)\n",
    "        self.address_books = address_books\n",
    "\n",
    "    def prediction(self, X):\n",
    "        res = []\n",
    "        for i in range(X.shape[0]):\n",
    "            cos = cosine_similarity(X[i],self.train).argsort()[:,:30][0] # 30 mails les plus proches\n",
    "            if self.N != 0:\n",
    "                NN_recpt = {}\n",
    "                for j in range(30):\n",
    "                    for k in range(len(self.predict[cos[j]])):\n",
    "                        if self.predict[cos[j]][k] in NN_recpt:\n",
    "                            NN_recpt[self.predict[cos[j]][k]]+= 1\n",
    "                        else:\n",
    "                            NN_recpt[self.predict[cos[j]][k]] = 1\n",
    "                res_temp = list(dict(sorted(NN_recpt.items(), key=operator.itemgetter(1), reverse=True)[:10]))\n",
    "            else:\n",
    "                 res_temp = []\n",
    "            # if less than 10 recipients, complete the prediction with more frequents users\n",
    "            if len(res_temp) < 10:\n",
    "                res_temp.extend(complete_prediction(10-len(res_temp),self.sender, self.address_books, res_temp))\n",
    "            res.append(res_temp)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Cross validation module</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sender_nb |                                   sender |   accuracy | accuracy freq\n",
      "---------- + ---------------------------------------- + ---------- + -------------\n",
      "         0 |                    mark.palmer@enron.com |       0.29 |          0.47\n",
      "         1 |                stephanie.panus@enron.com |       0.34 |          0.52\n",
      "         2 |                  james.derrick@enron.com |       0.11 |          0.38\n",
      "         3 |                  chris.germany@enron.com |       0.04 |          0.09\n",
      "         4 |                  lorna.brennan@enron.com |       0.68 |          0.82\n",
      "         5 |                     matt.smith@enron.com |       0.05 |          0.12\n",
      "         6 |                sara.shackleton@enron.com | "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-03f6e9ebf179>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mpdt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictor_KNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tfidf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender_train_is\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender_train_is\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddress_books\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mpdt_freq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictor_KNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tfidf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender_train_is\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender_train_is\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddress_books\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender_test_is\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tfidf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender_test_is\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0my_pred_freq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender_test_is\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdt_freq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tfidf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender_test_is\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-66cb2027095a>\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mcos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# 30 mails les plus proches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mNN_recpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Antoine/anaconda3/lib/python3.5/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0mY_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_normalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Antoine/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     X = check_array(X, sparse_format, copy=copy, warn_on_dtype=True,\n\u001b[0;32m-> 1344\u001b[0;31m                     estimator='the normalize function', dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Antoine/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n",
      "\u001b[0;32m/Users/Antoine/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;34m\"\"\"Return number of samples in array-like x.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Don't get num_samples from an ensembles length!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         raise TypeError('Expected sequence or array-like, got '\n",
      "\u001b[0;32m/Users/Antoine/anaconda3/lib/python3.5/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'A'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# splitting data for cross validation\n",
    "skf = ShuffleSplit(n_splits=1, test_size=0.2)\n",
    "print('%10s | %40s | %10s | %10s' %('sender_nb', 'sender', 'accuracy','accuracy freq'))\n",
    "print('%10s + %40s + %10s + %13s' %(10*'-', 40*'-', 10*'-', 13*'-'))\n",
    "\n",
    "for train_is, test_is in skf.split(y_df):\n",
    "    \n",
    "    X_tfidf_train = X_TFIDF[train_is].copy()\n",
    "    y_train = y_df.recipients.loc[train_is].copy()\n",
    "    X_tfidf_test = X_TFIDF[test_is].copy()\n",
    "    y_test = y_df.recipients.loc[test_is].copy()\n",
    "    X_test_df = X_df.loc[test_is].copy()\n",
    "    X_train_df = X_df.loc[train_is].copy()\n",
    "    \n",
    "    i=0\n",
    "    pdt = {}\n",
    "    pdt_freq = {}\n",
    "    accuracy = {}\n",
    "    accuracy_freq = {}\n",
    "    accuracy_TOT = 0\n",
    "    sender_test = X_test_df.sender.unique().tolist()\n",
    "    y_pred = np.empty((X_test_df.shape[0],10),dtype=object)\n",
    "    y_pred_freq = np.empty((X_test_df.shape[0],10),dtype=object)\n",
    "\n",
    "    for sender in sender_test:\n",
    "        print('%10s | %40s | ' %(sender_test.index(sender), sender), end='')\n",
    "        # indices corresponding to the sender\n",
    "        sender_train_is = np.array(X_train_df.sender == sender)\n",
    "        sender_test_is = np.array(X_test_df.sender == sender)\n",
    "        \n",
    "        pdt[sender] = Predictor_KNN(X_tfidf_train[sender_train_is], y_train[sender_train_is], sender, address_books)\n",
    "        pdt_freq[sender] = Predictor_KNN(X_tfidf_train[sender_train_is], y_train[sender_train_is], sender, address_books, N=0)\n",
    "        y_pred[sender_test_is] = pdt[sender].prediction(X_tfidf_test[sender_test_is])\n",
    "        y_pred_freq[sender_test_is] = pdt_freq[sender].prediction(X_tfidf_test[sender_test_is])\n",
    "        \n",
    "        accuracy[sender] = mapk(y_test[sender_test_is], y_pred[sender_test_is])\n",
    "        accuracy_freq[sender] = mapk(y_test[sender_test_is], y_pred_freq[sender_test_is])\n",
    "        \n",
    "        accuracy_TOT += accuracy[sender]\n",
    "        print('%10s | %13s' %(round(accuracy[sender],2),round(accuracy_freq[sender],2)))\n",
    "\n",
    "    print('%30s'%(90*'-'))\n",
    "    print('error TOT = %.2f' %(accuracy_TOT/len(accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2>Create submission</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_submission(y_pred,X_test_df):\n",
    "\n",
    "    predictions_towrite={}\n",
    "    x_test=X_test_df.values\n",
    "    for i in range(len(y_pred)):\n",
    "        recipients=y_pred[i]\n",
    "        mid=x_test[i][0]\n",
    "\n",
    "        if mid==180226:\n",
    "            print(i)\n",
    "        predictions_towrite[mid]=recipients\n",
    "\n",
    "    count=0\n",
    "    with open('./pred_custom.txt', 'w') as my_file:\n",
    "        my_file.write('mid,recipients' + '\\n')\n",
    "        for ids, preds in predictions_towrite.items():\n",
    "            count=count+1\n",
    "            r=str(ids)+\",\"\n",
    "            for s in preds:\n",
    "                r=r+\" \"+str(s)\n",
    "            r=r+'\\n'\n",
    "            my_file.write(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sender_test = X_sub_df.sender.unique().tolist()\n",
    "y_pred = np.empty((X_sub_df.shape[0],10),dtype=object)\n",
    "count=0\n",
    "pdt = {}\n",
    "\n",
    "for sender in sender_test:\n",
    "    # indices corresponding to the sender\n",
    "    sender_train_is = np.array(X_df.sender == sender)\n",
    "    sender_test_is = np.array(X_sub_df.sender == sender)\n",
    "\n",
    "    pdt[sender] = Predictor_1(X_TFIDF[sender_train_is], y_df[sender_train_is], sender, address_books)\n",
    "    y_pred[sender_test_is] = pdt[sender].predict_1(X_sub_tfidf[sender_test_is])\n",
    "    \n",
    "from create_submission import *\n",
    "\n",
    "create_submission(y_pred,X_sub_df)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
